{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **The fifth in-class-exercise (40 points in total, 4/18/2023)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
    "\n",
    "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
    "\n",
    "Algorithms:\n",
    "\n",
    "(1) MultinominalNB\n",
    "\n",
    "(2) SVM \n",
    "\n",
    "(3) KNN \n",
    "\n",
    "(4) Decision tree\n",
    "\n",
    "(5) Random Forest\n",
    "\n",
    "(6) XGBoost\n",
    "\n",
    "(7) Word2Vec\n",
    "\n",
    "(8) BERT\n",
    "\n",
    "Evaluation measurement:\n",
    "\n",
    "(1) Accuracy\n",
    "\n",
    "(2) Recall\n",
    "\n",
    "(3) Precison \n",
    "\n",
    "(4) F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stsa-train.txt\") as txtf:\n",
    "    list_1 = [line.rstrip('\\n') for line in txtf]\n",
    "    \n",
    "labels_1 = []\n",
    "text_1 = []\n",
    "\n",
    "for i, line in enumerate(list_1):\n",
    "    label_1 = list_1[i][0]\n",
    "    tex_1 = list_1[i][1:]\n",
    "    labels_1.append(label_1)\n",
    "    text_1.append(tex_1)\n",
    "\n",
    "df = pd.DataFrame(list(zip(labels_1, text_1)),columns =['Reviews', 'Text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "df['cleanText']=df['Text'].map(lambda s:preprocess(s)) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stsa-test.txt\") as txtf:\n",
    "    test_mylist = [line.rstrip('\\n') for line in txtf]\n",
    "    \n",
    "test_labels = []\n",
    "test_text = []\n",
    "\n",
    "for i, line in enumerate(test_mylist):\n",
    "    label_test = test_mylist[i][0]\n",
    "    tex_test = test_mylist[i][1:]\n",
    "    test_labels.append(label_test)\n",
    "    test_text.append(tex_test)\n",
    "\n",
    "df_test = pd.DataFrame(list(zip(test_labels, test_text)),columns =['Reviews', 'Text'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "df_test['cleanText']=df_test['Text'].map(lambda s:preprocess(s)) \n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase = False, analyzer='word')\n",
    "train_tfidf = tfidf_vectorizer.fit_transform(df[\"cleanText\"]).toarray()\n",
    "test_tfidf = tfidf_vectorizer.transform(df_test[\"cleanText\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = test_tfidf\n",
    "ytest = df_test[\"Reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, x_valid, ytrain, y_valid = train_test_split(train_tfidf,df[\"Reviews\"],test_size = 0.2, random_state = 202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "1. MultinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "model = classifier.fit(xtrain, ytrain) \n",
    "predictions_validation_set = classifier.predict(x_valid) \n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "print (\"Accuracy of the Naive Bayes model on validation set is : \", round(accuracy_score(y_valid, predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_naive_validation = classification_report(y_valid, predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "naive_accuracies_validation = cross_val_score(estimator = classifier, X = xtrain, y = ytrain, cv = 10)\n",
    "\n",
    "print(f\"Naive Bayes Model  10-fold cross validation score on training set is :  {round(naive_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_set = classifier.predict(xtest) \n",
    "print (\"Accuracy of the Naive Bayes model on test set is : \", round(accuracy_score(ytest, predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(ytest, predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(ytest, predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(ytest, predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_naive_test = classification_report(ytest, predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_accuracies_test = cross_val_score(estimator = classifier, X = xtest, y = ytest, cv = 10)\n",
    "\n",
    "print(f\"Naive Bayes Model 10-fold cross validation score on testing set is :  {round(naive_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "classifier_svm = svm.SVC()\n",
    "model_svm = classifier_svm.fit(xtrain, ytrain) \n",
    "svm_predictions_validation_set = classifier_svm.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the SVM model on validation set is : \", round(accuracy_score(y_valid, svm_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the SVM model on validation set is : \", round(precision_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the SVM model on validation set is : \", round(recall_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_svm_validation = classification_report(y_valid, svm_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "svm_accuracies_validation = cross_val_score(estimator = classifier_svm, X = xtrain, y = ytrain, cv = 10)\n",
    "\n",
    "print(f\"SVM Model  10-fold cross validation score on training set is :  {round(svm_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions_test_set = classifier_svm.predict(xtest) \n",
    "print (\"Accuracy of the SVM model on test set is : \", round(accuracy_score(ytest, svm_predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the SVM model on validation set is : \", round(precision_score(ytest, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the SVM model on validation set is : \", round(recall_score(ytest, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(ytest, svm_predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_svm_test = classification_report(ytest, svm_predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_accuracies_test = cross_val_score(estimator = classifier_svm, X = xtest, y = ytest, cv = 10)\n",
    "\n",
    "print(f\"SVM Model 10-fold cross validation score on testing set is :  {round(svm_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors = 15)\n",
    "model_knn = classifier_knn.fit(xtrain, ytrain) \n",
    "knn_predictions_validation_set = classifier_knn.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the KNN model on validation set is : \", round(accuracy_score(y_valid, knn_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the KNN model on validation set is : \", round(precision_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the KNN model on validation set is : \", round(recall_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_knn_validation = classification_report(y_valid, knn_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "knn_accuracies_validation = cross_val_score(estimator = classifier_knn, X = xtrain, y = ytrain, cv = 10)\n",
    "\n",
    "print(f\"KNN Model  10-fold cross validation score on training set is :  {round(knn_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predictions_test_set = classifier_knn.predict(xtest) \n",
    "print (\"Accuracy of the KNN model on test set is : \", round(accuracy_score(ytest, knn_predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the KNN model on validation set is : \", round(precision_score(ytest, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the KNN model on validation set is : \", round(recall_score(ytest, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(ytest, knn_predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_knn_test = classification_report(ytest, knn_predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracies_test = cross_val_score(estimator = classifier_knn, X = xtest, y = ytest, cv = 10)\n",
    "\n",
    "print(f\"KNN Model 10-fold cross validation score on testing set is :  {round(knn_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decison Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier_dt = DecisionTreeClassifier()\n",
    "model_dt = classifier_dt.fit(xtrain, ytrain) \n",
    "dt_predictions_validation_set = classifier_dt.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the Decison Tree Classifier model on validation set is : \", round(accuracy_score(y_valid, dt_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the Decison Tree Classifier model on validation set is : \", round(precision_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Decison Tree Classifier model on validation set is : \", round(recall_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Decison Tree Classifier model on validation set is : \", round(f1_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_dt_validation = classification_report(y_valid, dt_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "dt_accuracies_validation = cross_val_score(estimator = classifier_dt, X = xtrain, y = ytrain, cv = 10)\n",
    "\n",
    "print(f\"Decison Tree Classifier Model  10-fold cross validation score on training set is :  {round(dt_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions_test_set = classifier_dt.predict(xtest) \n",
    "print (\"Accuracy of the Decison Tree Classifier model on test set is : \", round(accuracy_score(ytest, dt_predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the Decison Tree Classifier model on validation set is : \", round(precision_score(ytest, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Decison Tree Classifier model on validation set is : \", round(recall_score(ytest, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Decison Tree Classifier model on validation set is : \", round(f1_score(ytest, dt_predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_dt_test = classification_report(ytest, dt_predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_accuracies_test = cross_val_score(estimator = classifier_dt, X = xtest, y = ytest, cv = 10)\n",
    "\n",
    "print(f\"Decison Tree Classifier Model 10-fold cross validation score on testing set is :  {round(dt_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_rf = RandomForestClassifier()\n",
    "model_rf = classifier_rf.fit(xtrain, ytrain) \n",
    "rf_predictions_validation_set = classifier_rf.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the Random Forest Classifier model on validation set is : \", round(accuracy_score(y_valid, rf_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the Random Forest Classifier model on validation set is : \", round(precision_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Random Forest Classifier model on validation set is : \", round(recall_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Random Forest Classifier model on validation set is : \", round(f1_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_rf_validation = classification_report(y_valid, rf_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "rf_accuracies_validation = cross_val_score(estimator = classifier_rf, X = xtrain, y = ytrain, cv = 10)\n",
    "\n",
    "print(f\"Decison Random Forest Model  10-fold cross validation score on training set is :  {round(rf_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_test_set = classifier_rf.predict(xtest) \n",
    "print (\"Accuracy of the Random Forest Classifier model on test set is : \", round(accuracy_score(ytest, rf_predictions_test_set)*100),\"%\")\n",
    "print (\"Percision of the Random Forest Classifier model on validation set is : \", round(precision_score(ytest, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"Recall of the Random Forest Classifier model on validation set is : \", round(recall_score(ytest, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
    "print (\"F1 Score of the Random Forest Classifier model on validation set is : \", round(f1_score(ytest, rf_predictions_test_set, pos_label='0')*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_rf_test = classification_report(ytest, rf_predictions_test_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_accuracies_test = cross_val_score(estimator = classifier_rf, X = xtest, y = ytest, cv = 10)\n",
    "\n",
    "print(f\"Random Forest Classifier Model 10-fold cross validation score on testing set is :  {round(rf_accuracies_test.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Convert y_train and y_valid to integers\n",
    "ytrain = ytrain.astype(int)\n",
    "y_valid = y_valid.astype(int)\n",
    "\n",
    "classifier_xgb = XGBClassifier()\n",
    "model_xgb = classifier_xgb.fit(xtrain, ytrain) \n",
    "xgb_predictions_validation_set = classifier_xgb.predict(x_valid) \n",
    "\n",
    "print (\"Accuracy of the XGBoost Classifier model on validation set is : \", round(accuracy_score(y_valid, xgb_predictions_validation_set)*100),\"%\")\n",
    "print (\"Percision of the XGBoost Classifier model on validation set is : \", round(precision_score(y_valid, xgb_predictions_validation_set, pos_label=0)*100),\"%\")\n",
    "print (\"Recall of the XGBoost Classifier model on validation set is : \", round(recall_score(y_valid, xgb_predictions_validation_set, pos_label=0)*100),\"%\")\n",
    "print (\"F1 Score of the XGBoost Classifier model on validation set is : \", round(f1_score(y_valid, xgb_predictions_validation_set, pos_label=0)*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cr_xgb_validation = classification_report(y_valid, xgb_predictions_validation_set)\n",
    "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_xgb_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "xgb_accuracies_validation = cross_val_score(estimator = classifier_xgb, X = xtrain, y = y_train, cv = 10)\n",
    "\n",
    "print(f\"XGBoost Model  10-fold cross validation score on training set is :  {round(xgb_accuracies_validation.mean()*100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
    "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
    "(You can also use different text data which you want)\n",
    "\n",
    "Apply the listed clustering methods to the dataset:\n",
    "\n",
    "K-means\n",
    "\n",
    "DBSCAN\n",
    "\n",
    "Hierarchical clustering\n",
    "\n",
    "Word2Vec\n",
    "\n",
    "BERT\n",
    "\n",
    "You can refer to of the codes from  the follwing link below. \n",
    "https://www.kaggle.com/karthik3890/text-clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
    "\n",
    "data_frame['Reviews']=data_frame['Reviews'].map(lambda s:preprocess(s)) \n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF VECTORIZATION\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vects = tfidf_vect.fit_transform(data_frame['Reviews'].values.astype('U'))\n",
    "names= tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ELBOW METHOD\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "wcss_1 = []\n",
    "for i in range(2,12):\n",
    "    kmeans = KMeans(n_clusters = i, init = \"k-means++\", random_state = 101)\n",
    "    kmeans.fit(tfidf_vects)\n",
    "    wcss_1.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize = (11,6))\n",
    "plt.plot(range(2,12), wcss_1, marker = \"o\")\n",
    "plt.title (\"The Elbow Method\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"WCSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters = 6,init='k-means++',max_iter=10000, random_state=50)\n",
    "model.fit(tfidf_vects)\n",
    "from collections import Counter\n",
    "Counter(model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_1 = 7\n",
    "centroids_1 = model.cluster_centers_.argsort()[:, ::-1]\n",
    "for cluster_num in range(6):\n",
    "    key_features = [names[i] for i in centroids_1[cluster_num, :top_words_1]]\n",
    "    print('Cluster '+str(cluster_num+1))\n",
    "    print('Top Words:', key_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_center=model.cluster_centers_\n",
    "cluster_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_1=[]\n",
    "for i in data_frame['Review']:\n",
    "    reviews_1.append(str(i).split())\n",
    "import gensim\n",
    "w2v_model=gensim.models.Word2Vec(reviews_1, size=100, workers=4)\n",
    "\n",
    "import numpy as np\n",
    "vectors_1 = []\n",
    "for i in reviews_1:\n",
    "    vector = np.zeros(100)\n",
    "    counter = 0\n",
    "    for word in i:\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            vector += vec\n",
    "            counter += 1\n",
    "        except:\n",
    "            pass\n",
    "    vector /= counter\n",
    "    vectors_1.append(vector)  \n",
    "vectors_1 = np.array(vectors_1)\n",
    "vectors_1 = np.nan_to_num(vectors_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "minPts = 2 * 100\n",
    "# Lower bound function\n",
    "def lower_bound(nums, target): \n",
    "    l, r = 0, len(nums) - 1\n",
    "    # Binary searching\n",
    "    while l <= r:\n",
    "        mid_valueue = int(l + (r - l) / 2)\n",
    "        if nums[mid_valueue] >= target:\n",
    "            r = mid_valueue - 1\n",
    "        else:\n",
    "            l = mid_valueue + 1\n",
    "    return l\n",
    "\n",
    "def compute200thnearestneighbour(x, data): \n",
    "    dict_1 = []\n",
    "    for value in data:\n",
    "      # computing distances\n",
    "        dist = np.sum((x - value) **2 ) \n",
    "        if(len(dict_1) == 200 and dict_1[199] > dist): \n",
    "            l = int(lower_bound(dict_1, dist)) \n",
    "            if l < 200 and l >= 0 and dict_1[l] > dist:\n",
    "                dict_1[l] = dist\n",
    "        else:\n",
    "            dict_1.append(dist)\n",
    "            dict_1.sort()\n",
    "\n",
    "# Dist 199 contains the distance of 200th nearest neighbour.    \n",
    "    return dict_1[199]\n",
    "\n",
    "vectors_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the 200th nearest neighbour distance of some point the dataset:\n",
    "twohundrethneigh = []\n",
    "for value in vectors_1[:1000]:\n",
    "    twohundrethneigh.append( compute200thnearestneighbour(value, vectors_1[:1000]) )\n",
    "twohundrethneigh.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting for the Elbow Method :\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(14,4))\n",
    "plt.title(\"Elbow Method for Finding the right Eps hyperparameter\")\n",
    "plt.plot([x for x in range(len(twohundrethneigh))], twohundrethneigh)\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Distance of 200th Nearest Neighbour\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model_dbs = DBSCAN(eps = 5, min_samples = minPts)\n",
    "model_dbs.fit(vectors_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dbs = data_frame\n",
    "df_dbs[\"DBS Cluster Label\"] = model_dbs.labels_\n",
    "df_dbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.cluster import hierarchy\n",
    "dendro=hierarchy.dendrogram(hierarchy.linkage(vectors_1,method='ward'))\n",
    "plt.axhline(y=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  #took n=3 from dendrogram curve \n",
    "Agg=cluster.fit_predict(vectors_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['AVG-W2V Clus Label'] = cluster.labels_\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_data_frame = data_frame\n",
    "hier_data_frame[\"Hierarchial Cluster Labels\"] = cluster.labels_\n",
    "hier_data_frame.groupby([\"Hierarchial Cluster Labels\"])[\"Reviews\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can write you answer here. (No code needed)\n",
    "\"\"\"\"K-means clustering utilizes the concept of measuring the distance between data points and cluster centroids. On the other hand, DBSCAN performs clustering based on the density of data points, detecting areas of high concentration and separating them from sparse regions. Hierarchical clustering operates in a hierarchical manner, initially considering each data point as an individual cluster, and gradually merging the nearest clusters together until all data points belong to a single cluster.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
